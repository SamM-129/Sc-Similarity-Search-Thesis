{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8f4ed4d-233e-4a2e-b645-338691083d42",
   "metadata": {},
   "source": [
    "This notebook collects query time, recall, and memory use in the inverted file index solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53fa64d2-a07f-45da-a1be-aae39c9e0b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import faiss\n",
    "import numpy as np\n",
    "import itertools\n",
    "import statistics\n",
    "import matplotlib.cm as cm\n",
    "import time\n",
    "import os\n",
    "from time import perf_counter_ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c10c1ac7-9daf-41ba-8fa4-958ab88aefc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['embed_all', 'embed_raw', 'embed_l2_norm', 'restore_order', 'embed_correct_coverage_fh', 'embed_l2_norm_correct_coverage_fh'])\n",
      "dict_keys(['batch id', 'age', 'total_cg', 'average_cg_rate', 'total_ch', 'average_ch_rate', 'hic_counts', 'cell_name_higashi', 'major', 'minor', 'cluster label', 'cluster label minor'])\n"
     ]
    }
   ],
   "source": [
    "# read in embeddings and cluster label info\n",
    "with open('embedding64.pickle', 'rb') as fp:\n",
    "    embedding64 = pickle.load(fp)\n",
    "with open('label_info.pickle', 'rb') as fp:\n",
    "    label_info = pickle.load(fp)\n",
    "\n",
    "print(embedding64.keys())\n",
    "print(label_info.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7952b9cd-2327-4407-ae86-3bd3be95a810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAJOR CLUSTERS\n",
      "    Sst: 217\n",
      "    L2/3: 551\n",
      "    Vip: 171\n",
      "    ODC: 1245\n",
      "    L5: 180\n",
      "    L6: 86\n",
      "    MG: 422\n",
      "    Pvalb: 134\n",
      "    Ndnf: 144\n",
      "    Endo: 205\n",
      "    MP: 100\n",
      "    Astro: 449\n",
      "    L4: 131\n",
      "    OPC: 203\n",
      "MINOR CLUSTERS\n",
      "    L6-2: 19\n",
      "    Endo-2: 69\n",
      "    Endo-3: 85\n",
      "    Astro-1: 449\n",
      "    L2/3-1: 137\n",
      "    MP-1: 100\n",
      "    Vip-1: 45\n",
      "    Vip-2: 126\n",
      "    MG-1: 422\n",
      "    OPC-1: 203\n",
      "    ODC-1: 810\n",
      "    L5-1: 48\n",
      "    L4-1: 131\n",
      "    Ndnf-2: 63\n",
      "    L5-3: 58\n",
      "    L6-1: 67\n",
      "    Pvalb-2: 21\n",
      "    Pvalb-1: 113\n",
      "    Sst-1: 50\n",
      "    L2/3-2: 137\n",
      "    L2/3-3: 127\n",
      "    Endo-1: 51\n",
      "    L2/3-4: 150\n",
      "    Sst-2: 107\n",
      "    Sst-3: 60\n",
      "    L5-2: 74\n",
      "    Ndnf-1: 59\n",
      "    ODC-2: 435\n",
      "    Ndnf-3: 22\n"
     ]
    }
   ],
   "source": [
    "# create helpful dicts for the cluster labels\n",
    "# also look at n counts for the clusters\n",
    "major_labels = list(set(label_info['cluster label']))\n",
    "minor_labels = list(set(label_info['cluster label minor']))\n",
    "\n",
    "major = dict(zip(major_labels,[[] for item in major_labels]))\n",
    "minor = dict(zip(minor_labels,[[] for item in minor_labels]))\n",
    "\n",
    "true_major = label_info['cluster label']\n",
    "true_minor = label_info['cluster label minor']\n",
    "\n",
    "for j in range(len(label_info['cluster label'])):\n",
    "    maj = label_info['cluster label'][j]\n",
    "    min = label_info['cluster label minor'][j]\n",
    "\n",
    "    if maj in major.keys():\n",
    "        major[maj].append(j)\n",
    "    if min in minor.keys():\n",
    "        minor[min].append(j)\n",
    "\n",
    "print(\"MAJOR CLUSTERS\")\n",
    "for key in major.keys():\n",
    "    s = \"    \" + key + \": \" + str(len(major[key]))\n",
    "    print(s)\n",
    "    \n",
    "print(\"MINOR CLUSTERS\")\n",
    "for key in minor.keys():\n",
    "    s = \"    \" + key + \": \" + str(len(minor[key]))\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63103574-f412-413d-8a83-7975d71cf77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get memory footprint for index\n",
    "# source: https://www.pinecone.io/learn/series/faiss/product-quantization/\n",
    "def get_memory(index):\n",
    "    faiss.write_index(index,'./temp.index')\n",
    "    file_size = os.path.getsize('./temp.index')\n",
    "    os.remove('./temp.index')\n",
    "    return file_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "805db8d2-a008-440a-bef2-64e99b257c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate recall based on search results\n",
    "def get_recall_min(i, result_min):\n",
    "    # recall: TP / cluster size\n",
    "    return len(set(minor[true_minor[i]]).intersection(result_min)) / len(minor[true_minor[i]])\n",
    "\n",
    "def get_recall_maj(i, result_maj):\n",
    "    # recall: TP / cluster size\n",
    "    return len(set(major[true_major[i]]).intersection(result_maj)) / len(major[true_major[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59417a93-1abc-4424-9aeb-f7415196719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create input database\n",
    "database = np.array(embedding64[\"embed_l2_norm\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a61cfe8f-d2df-40c8-a98a-f6630dcecd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rep(index, query, k):\n",
    "    start1 = perf_counter_ns()\n",
    "    for x in range(100):\n",
    "        D, I = index.search(query, k)\n",
    "    end1 = perf_counter_ns()\n",
    "        \n",
    "    start2 = perf_counter_ns()\n",
    "    for x in range(100):\n",
    "        D, I = index.search(query, k)\n",
    "    end2 = perf_counter_ns()\n",
    "        \n",
    "    start3 = perf_counter_ns()\n",
    "    for x in range(100):\n",
    "        D, I = index.search(query, k)\n",
    "    end3 = perf_counter_ns()\n",
    "\n",
    "    times = [(end1-start1),(end2-start2),(end3-start3)]\n",
    "    times.sort()\n",
    "\n",
    "    return I, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ede2e358-eaeb-429b-b164-31fa2a141ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define experiment function\n",
    "def IVF_flat_experiment(nlist):\n",
    "    # initialize empty arrays for results\n",
    "    recall_min = np.zeros([32,4238])\n",
    "    recall_maj = np.zeros([32,4238])\n",
    "    speed_min = np.zeros([32,4238])\n",
    "    speed_maj = np.zeros([32,4238])\n",
    "    memory = np.zeros([4238])\n",
    "    \n",
    "    for i in range(4238):\n",
    "        # subset dataset\n",
    "        db_subset = np.delete(database, i, 0)\n",
    "        query = np.array([database[i]])\n",
    "        k_major = len(major[true_major[i]]) # size of true cluster (how many neighbors to return)\n",
    "        k_minor = len(minor[true_minor[i]]) # size of true cluster (how many neighbors to return)\n",
    "        \n",
    "        # create and train index\n",
    "        quantizer = faiss.IndexFlatL2(64)\n",
    "        index = faiss.IndexIVFFlat(quantizer, 64, nlist)\n",
    "        index.train(db_subset)\n",
    "        index.add(database)\n",
    "\n",
    "        # how much memory is used?\n",
    "        memory[i] = get_memory(index)\n",
    "                \n",
    "        # query index using nprobe values 1-16\n",
    "        recall_min_temp=[]\n",
    "        speed_min_temp=[]\n",
    "        recall_maj_temp=[]\n",
    "        speed_maj_temp=[]\n",
    "        \n",
    "        for n in range(1,33):\n",
    "            index.nprobe = n    \n",
    "\n",
    "            # major cluster query\n",
    "            I, time = query_rep(index, query, k_major)\n",
    "            recall_maj_temp.append(get_recall_maj(i, I[0]))\n",
    "            speed_maj_temp.append(time[0])\n",
    "\n",
    "            # minor cluster query\n",
    "            I, time = query_rep(index, query, k_minor)\n",
    "            recall_min_temp.append(get_recall_min(i, I[0]))\n",
    "            speed_min_temp.append(time[0])\n",
    "\n",
    "        # save results \n",
    "        recall_min[:,i]=recall_min_temp\n",
    "        speed_min[:,i]=speed_min_temp\n",
    "        recall_maj[:,i]=recall_maj_temp\n",
    "        speed_maj[:,i]=speed_maj_temp  \n",
    "\n",
    "    # return all results\n",
    "    return recall_min, recall_maj, speed_min, speed_maj, memory\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5ea9933-2822-455f-b633-e577a3d05c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXPERIMENT A: NLIST=17\n",
    "recall_min_A, recall_maj_A, speed_min_A, speed_maj_A, memory_A = IVF_flat_experiment(17)\n",
    "\n",
    "with open('IVFFLAT/ExperimentA.npy', 'wb') as f:\n",
    "    np.save(f, recall_min_A)\n",
    "    np.save(f, recall_maj_A)\n",
    "    np.save(f, speed_min_A)\n",
    "    np.save(f, speed_maj_A)\n",
    "    np.save(f, memory_A)\n",
    "\n",
    "# with open('IVFFLAT/ExperimentA.npy', 'rb') as f:\n",
    "#     recall_min_A = np.load(f)\n",
    "#     recall_maj_A = np.load(f)\n",
    "#     speed_min_A = np.load(f)\n",
    "#     speed_maj_A = np.load(f)\n",
    "#     memory_A = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74904e6b-a156-4900-a64c-a3c89bea7a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXPERIMENT B: NLIST=47\n",
    "recall_min_B, recall_maj_B, speed_min_B, speed_maj_B, memory_B = IVF_flat_experiment(47)\n",
    "\n",
    "with open('IVFFLAT/ExperimentB.npy', 'wb') as f:\n",
    "    np.save(f, recall_min_B)\n",
    "    np.save(f, recall_maj_B)\n",
    "    np.save(f, speed_min_B)\n",
    "    np.save(f, speed_maj_B)\n",
    "    np.save(f, memory_B)\n",
    "\n",
    "# with open('IVFFLAT/ExperimentB.npy', 'rb') as f:\n",
    "#     recall_min_B = np.load(f)\n",
    "#     recall_maj_B = np.load(f)\n",
    "#     speed_min_B = np.load(f)\n",
    "#     speed_maj_B = np.load(f)\n",
    "#     memory_B = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5376753b-d608-458b-b7a0-ee3943bccd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXPERIMENT C: NLIST=77\n",
    "recall_min_C, recall_maj_C, speed_min_C, speed_maj_C, memory_C = IVF_flat_experiment(77)\n",
    "\n",
    "with open('IVFFLAT/ExperimentC.npy', 'wb') as f:\n",
    "    np.save(f, recall_min_C)\n",
    "    np.save(f, recall_maj_C)\n",
    "    np.save(f, speed_min_C)\n",
    "    np.save(f, speed_maj_C)\n",
    "    np.save(f, memory_C)\n",
    "\n",
    "# with open('IVFFLAT/ExperimentC.npy', 'rb') as f:\n",
    "#     recall_min_C = np.load(f)\n",
    "#     recall_maj_C = np.load(f)\n",
    "#     speed_min_C = np.load(f)\n",
    "#     speed_maj_C = np.load(f)\n",
    "#     memory_C = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dac8a9d-e5e2-45eb-8a2e-5c3ad3361975",
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXPERIMENT D: NLIST=107\n",
    "recall_min_D, recall_maj_D, speed_min_D, speed_maj_D, memory_D = IVF_flat_experiment(107)\n",
    "\n",
    "with open('IVFFLAT/ExperimentD.npy', 'wb') as f:\n",
    "    np.save(f, recall_min_D)\n",
    "    np.save(f, recall_maj_D)\n",
    "    np.save(f, speed_min_D)\n",
    "    np.save(f, speed_maj_D)\n",
    "    np.save(f, memory_D)\n",
    "\n",
    "# with open('IVFFLAT/ExperimentD.npy', 'rb') as f:\n",
    "#     recall_min_D = np.load(f)\n",
    "#     recall_maj_D = np.load(f)\n",
    "#     speed_min_D = np.load(f)\n",
    "#     speed_maj_D = np.load(f)\n",
    "#     memory_D = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67d737a7-a45c-4ca6-815f-d70b96809751",
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXPERIMENT E: NLIST=137\n",
    "recall_min_E, recall_maj_E, speed_min_E, speed_maj_E, memory_E = IVF_flat_experiment(137)\n",
    "\n",
    "with open('IVFFLAT/ExperimentE.npy', 'wb') as f:\n",
    "    np.save(f, recall_min_E)\n",
    "    np.save(f, recall_maj_E)\n",
    "    np.save(f, speed_min_E)\n",
    "    np.save(f, speed_maj_E)\n",
    "    np.save(f, memory_E)\n",
    "\n",
    "# with open('IVFFLAT/ExperimentE.npy', 'rb') as f:\n",
    "#     recall_min_E = np.load(f)\n",
    "#     recall_maj_E = np.load(f)\n",
    "#     speed_min_E = np.load(f)\n",
    "#     speed_maj_E = np.load(f)\n",
    "#     memory_E = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe16d8a-eeea-4586-87d3-cb7c160bee8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
