{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b48df080-98f6-41af-babd-0c447ce48273",
   "metadata": {},
   "source": [
    "This notebook contains code that can be used to download the raw single cell Hi-C data  \n",
    "\n",
    "The GEO source\n",
    "    https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE130711\n",
    "\n",
    "An alternative/easier way to access the data (instead of doing all this) is to download data.txt from this Google Drive  \n",
    "    https://drive.google.com/drive/folders/1SuzqQ_9dliAmTb-fGprFnN3aZrfWS-Fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8cca1b-4125-4ec6-98c1-ab0903f5749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from urllib.request import urlretrieve\n",
    "import gzip\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66b6a49-712a-43ae-8d49-68c6709423a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in meta data for the experiment \n",
    "# (file names and geo accession n for all 4238 samples)\n",
    "\n",
    "chunk_size = 4096\n",
    "# convert from gzip to txt\n",
    "with gzip.open('GSE130711-GPL20301_series_matrix.txt.gz', 'rb') as f_in:\n",
    "  with open('matrix1.txt', 'wb') as f_out:\n",
    "    chunk = f_in.read(chunk_size)\n",
    "    while chunk:\n",
    "      f_out.write(chunk)\n",
    "      chunk = f_in.read(chunk_size) \n",
    "        \n",
    "with gzip.open('GSE130711-GPL24676_series_matrix.txt.gz', 'rb') as f_in:\n",
    "  with open('matrix2.txt', 'wb') as f_out:\n",
    "    chunk = f_in.read(chunk_size)\n",
    "    while chunk:\n",
    "      f_out.write(chunk)\n",
    "      chunk = f_in.read(chunk_size) \n",
    "\n",
    "# read in txt files\n",
    "with open(\"matrix1.txt\", mode=\"r\") as file:\n",
    "    matrix1 = file.readlines()\n",
    "with open(\"matrix2.txt\", mode=\"r\") as file:\n",
    "    matrix2 = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d4df60-f700-486a-a833-d84e3bb63c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract ftp links and geo accession numbers\n",
    "for item in matrix1:    \n",
    "    if item.startswith(\"!Sample_geo_accession\"):\n",
    "        geo1 = item.replace('\"','').split()[1:]\n",
    "    elif item.startswith(\"!Sample_supplementary_file_1\"):\n",
    "        ftp1 = item.replace('\"','').split()[1:]\n",
    "\n",
    "for item in matrix2:    \n",
    "    if item.startswith(\"!Sample_geo_accession\"):\n",
    "        geo2 = item.replace('\"','').split()[1:]\n",
    "    elif item.startswith(\"!Sample_supplementary_file_1\"):\n",
    "        ftp2 = item.replace('\"','').split()[1:]\n",
    "\n",
    "geo = geo1 + geo2\n",
    "ftp = ftp1 + ftp2\n",
    "print(len(geo))\n",
    "print(len(ftp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f605ecd6-0f79-49bb-908c-c89a6b49d968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the files and then use 7zip to open after\n",
    "zipfilenames = ['zipped/' + geos.strip() + '.gz' for geos in geo]\n",
    "\n",
    "def download_zip(min, max):\n",
    "    print(\"Downloading zip file...\")\n",
    "    \n",
    "    for i in range(min,max):\n",
    "        try:\n",
    "            print(\"  %s of %s\" % (i+1, max))\n",
    "            urlretrieve(ftp[i],zipfilenames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee383cf3-5d6f-499e-8dc0-d1e12ec5588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-500\n",
    "download_zip(0,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa6f094-29f2-4086-bd07-c88292689e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 501-1000\n",
    "download_zip(500,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a048f6ac-780a-401e-abc1-4eddda250418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1001-1500\n",
    "download_zip(1000,1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2dcda2-13d3-4dd6-864b-363b26293127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1501-2000\n",
    "download_zip(1500,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06a67e1-dd82-4552-8f0c-be4f8a86818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2001-2500\n",
    "download_zip(2000,2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0a72d4-865c-4277-9c8b-7865a6bff1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2501-3000\n",
    "download_zip(2500,3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1fdbee-4eb9-4f6d-9cf5-e39c849bc935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3001-3500\n",
    "download_zip(3000,3500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a782b5c-decb-4c33-922e-11aaf762b8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3501-4000\n",
    "download_zip(3500,4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074043e7-1a3a-4e9a-8deb-1d00e3a9d066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4000-4238\n",
    "download_zip(4000,4238)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50047755-6b66-434f-89ec-3fac4f0397e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1c517c-3009-47b6-91cc-28c0b6d9a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict with file names and geo accession numbers\n",
    "geodict = {}\n",
    "\n",
    "for i in range(len(geo)):\n",
    "    longftp = ftp[i]\n",
    "    geoacst = geo[i]+'_'\n",
    "    x = longftp.index(geoacst)\n",
    "    longftp = longftp[x+len(geoacst):-3]\n",
    "    geodict[geo[i]] = longftp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a070a8-63df-423a-9b41-d5b46cbff984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move all files into the same directory and rename\n",
    "directories2 = []\n",
    "with open(\"directories2.txt\", mode=\"r\") as file:\n",
    "    for line in file:\n",
    "        directories2.append(file.readline().replace('\\n','').strip())\n",
    "directories2[1:5]\n",
    "\n",
    "counter=0\n",
    "for i in range(len(directories2)):\n",
    "    g = directories2[i]\n",
    "    if g=='':\n",
    "        # do nothing\n",
    "        x=1\n",
    "    else:\n",
    "        x = len(os.listdir('samples/'+g))\n",
    "        if x>0:\n",
    "            oldfile = 'samples/'+g+'/'+geodict[g]\n",
    "            newfile = 'samples/' + g+'.txt'\n",
    "            shutil.move(oldfile, newfile)\n",
    "            counter = counter + 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6936ce7-3aff-4a62-846e-951943ef1662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move all files into the same directory and rename\n",
    "directories3 = []\n",
    "with open(\"directories3.txt\", mode=\"r\") as file:\n",
    "    for line in file:\n",
    "        directories3.append(line.replace('\\n','').strip())\n",
    "print(len(directories3))\n",
    "\n",
    "counter=0\n",
    "for i in range(len(directories3)):\n",
    "    g = directories3[i]\n",
    "    if g=='':\n",
    "        x=1\n",
    "    else:\n",
    "        x = len(os.listdir('samples/'+g))\n",
    "        if x>0:\n",
    "            oldfile = 'samples/'+g+'/'+geodict[g]\n",
    "            newfile = 'samples/' + g+'.txt'\n",
    "            shutil.move(oldfile, newfile)\n",
    "            counter = counter + 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a69d8b3-3cbf-478d-9c16-6eb2f2fa9c86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read all the txt files and ensure there are no data issues\n",
    "# should contain:\n",
    "# col1: cell_id\n",
    "# col2: chrom1\n",
    "# col3: chrom1 position\n",
    "# col4: chrom2\n",
    "# col5: chrom2 position\n",
    "chrom = ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', \n",
    "         'chr6', 'chr7', 'chr8', 'chr9', 'chr10', \n",
    "         'chr11', 'chr12', 'chr13', 'chr14', 'chr15',\n",
    "         'chr16', 'chr17', 'chr18', 'chr19', 'chr20', \n",
    "         'chr21', 'chr22']\n",
    "\n",
    "geo_file_missing = []\n",
    "geo_file_present = []\n",
    "\n",
    "for i in range(len(geo)):\n",
    "    try:\n",
    "        filename = \"samples/\" + geo[i].strip() + '.txt'\n",
    "        print(str(i+1) + \" of \" + str(len(geo)))\n",
    "        with open(filename, mode=\"r\") as file:\n",
    "            ind=0\n",
    "            for line in file:\n",
    "                keep=False\n",
    "                c = line.split()\n",
    "                if c[1] in chrom and c[3] in chrom and c[2].isdigit() and c[4].isdigit():\n",
    "                    keep=True \n",
    "                    ind=ind+1\n",
    "            if ind>0:\n",
    "                geo_file_present.append(geo[i])\n",
    "            else:\n",
    "                geo_file_missing.append(geo[i])\n",
    "    except OSError as err:\n",
    "        geo_file_missing.append(geo[i])\n",
    "        print(err)\n",
    "    except ValueError as err:\n",
    "        geo_file_missing.append(geo[i])\n",
    "        print(err)\n",
    "        print(c)\n",
    "    except Exception as err:\n",
    "        geo_file_missing.append(geo[i])\n",
    "        print(err)\n",
    "        print(c)\n",
    "\n",
    "print(paste(\"Missing:\",len(geo_file_missing)))\n",
    "print(paste(\"Not Missing:\",len(geo_file_present)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87018fdc-1f48-45e7-8191-ba602de90d5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use the same code to concatenate all the files into one big \"data.txt\" file\n",
    "# should contain:\n",
    "# col1: cell_id\n",
    "# col2: chrom1\n",
    "# col3: chrom1 position\n",
    "# col4: chrom2\n",
    "# col5: chrom2 position\n",
    "# col6: count\n",
    "chrom = ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', \n",
    "         'chr6', 'chr7', 'chr8', 'chr9', 'chr10', \n",
    "         'chr11', 'chr12', 'chr13', 'chr14', 'chr15',\n",
    "         'chr16', 'chr17', 'chr18', 'chr19', 'chr20', \n",
    "         'chr21', 'chr22']\n",
    "\n",
    "geo_file_missing = []\n",
    "geo_lines = []\n",
    "geo2 = []\n",
    "\n",
    "with open('data.txt', 'w') as f_out:\n",
    "    out = 'cell_id\\tchrom1\\tpos1\\tchrom2\\tpos2\\tcount\\n'\n",
    "    f_out.write(out)\n",
    "    id = -1\n",
    "    for i in range(len(geo)):\n",
    "        lines=0\n",
    "        print(str(i+1) + \" of \" + str(len(geo)))\n",
    "        try:\n",
    "            filename = \"samples/\" + geo[i].strip() + '.txt'\n",
    "            with open(filename, mode=\"r\") as file:\n",
    "                id = id+1\n",
    "                for line in file:\n",
    "                    try:\n",
    "                        c = line.split()\n",
    "                        if c[1] in chrom and c[3] in chrom and c[2].isdigit() and c[4].isdigit():\n",
    "                            out= str(id) + '\\t' + c[1].strip() + '\\t' + c[2].strip() + '\\t' + c[3].strip() + '\\t' + c[2].strip() + '\\t1' + '\\n'\n",
    "                            f_out.write(out)\n",
    "                            lines = lines+1\n",
    "                    except OSError as err:\n",
    "                        # skip line\n",
    "                        x=1\n",
    "                    except ValueError as err:\n",
    "                        # skip line\n",
    "                        x=1\n",
    "                    except Exception as err:\n",
    "                        # skip line\n",
    "                        x=1    \n",
    "                geo2.append(geo[i])\n",
    "        except OSError as err:\n",
    "            geo_file_missing.append(geo[i])\n",
    "            print(err)\n",
    "        except ValueError as err:\n",
    "            geo_file_missing.append(geo[i])\n",
    "            print(err)\n",
    "        except Exception as err:\n",
    "            geo_file_missing.append(geo[i])\n",
    "            print(err)\n",
    "            \n",
    "        geo_lines.append(lines)\n",
    "            \n",
    "print(\"Missing:\",str(len(geo_file_missing)))\n",
    "print(\"Included:\",str(len(geo2)))\n",
    "print(\"id is n-1? \", str(id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e884560-946e-4f1a-a1d4-8c097e61b382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "label_info_src = pd.read_pickle(\"label_info_src.pickle\")\n",
    "label_info_src.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a66bf57-50a9-4e66-bce4-3c5c40442f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = label_info_src['batch id']\n",
    "cluster_major = label_info_src['major']\n",
    "cluster_minor = label_info_src['minor']\n",
    "cluster_major_lab = label_info_src['cluster label']\n",
    "cluster_minor_lab = label_info_src['cluster label minor']\n",
    "cell_name = label_info_src[\"cell_name_higashi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b89cae-0631-4e93-ad1e-24242ea5f100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict to translate from GEO accession number to sample title\n",
    "rep = ['\"',\"_snm3Cseq_hs\",\"_BA10_UMB5577_3_UMB5577\",\n",
    "       \"_BA10_UMB5577_1_UMB5577\",\"_BA10_UMB5580_1_UMB5580\",\n",
    "      \"_BA10_UMB5577_5_UMB5577\",\"_BA10_UMB5580_3_UMB5580\",\n",
    "      \"_BA10_UMB5580_5_UMB5580\"]\n",
    "\n",
    "for item in matrix1:    \n",
    "    if item.startswith(\"!Sample_title\"):\n",
    "        title1 = item\n",
    "        for r in rep:\n",
    "            title1 = title1.replace(r,\"\")\n",
    "        title1 = title1.split()[1:]\n",
    "\n",
    "for item in matrix2:    \n",
    "    if item.startswith(\"!Sample_title\"):\n",
    "        title2 = item\n",
    "        for r in rep:\n",
    "            title2 = title2.replace(r,\"\")\n",
    "        title2 = title2.split()[1:]\n",
    "        \n",
    "title = title1 + title2\n",
    "\n",
    "for item in title:\n",
    "    if not(item in cell_name):\n",
    "        print(item)\n",
    "\n",
    "geo_to_title = dict(zip(geo,title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d6412c-83a4-4358-94d8-f0ffd6254aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_final = []\n",
    "cluster_major_final = []\n",
    "cluster_minor_final = []\n",
    "cluster_major_lab_final = []\n",
    "cluster_minor_lab_final = []\n",
    "title_final = []\n",
    "\n",
    "for geonum in geo2:\n",
    "    index = cell_name.index(geo_to_title[geonum])\n",
    "    batch_final.append(batch[index])\n",
    "    cluster_major_final.append(cluster_major[index])\n",
    "    cluster_minor_final.append(cluster_minor[index])\n",
    "    cluster_major_lab_final.append(cluster_major_lab[index])\n",
    "    cluster_minor_lab_final.append(cluster_minor_lab[index])\n",
    "    title_final.append(cell_name[index])\n",
    "\n",
    "print(len(geo))\n",
    "print(len(batch_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5faa997-4374-4acf-81d4-23626c7f568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create file with cluster label information\n",
    "label_info = {'batch id': batch_final,\n",
    "              'major': cluster_major_final,\n",
    "              'minor': cluster_minor_final,\n",
    "              'major label':cluster_major_lab_final,\n",
    "              'minor label':cluster_minor_lab_final,\n",
    "              'title':title_final,\n",
    "              'geo':geo2\n",
    "             }\n",
    "\n",
    "pickle.dump(label_info, open(\"label_info.pickle\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
